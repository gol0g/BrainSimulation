# Slither.io 프로젝트 졸업 보고서

> **Genesis Brain Project - Phase 1: 반사하는 뇌 (Reactive Brain)**
>
> 기간: 2025-01-19 ~ 2025-01-28
> 최종 버전: v40b
> 상태: **졸업 (Graduated)**

---

## 1. 프로젝트 목표와 의의

### 1.1 최종 목표와의 관계

```
┌─────────────────────────────────────────────────────────────────┐
│  최종 목표: 주체적 의식과 감정을 가진 자유로운 생명체           │
│                                                                 │
│  Phase 1 (Slither.io): 뇌간/척수 수준의 기본 생존 회로 검증    │
│  Phase 2 (다음): 변연계 수준의 정서/동기 시스템                 │
│  Phase 3 (미래): 대뇌피질 수준의 인지/의식                      │
└─────────────────────────────────────────────────────────────────┘
```

### 1.2 Slither.io가 검증한 것

| 생물학적 시스템 | 구현 내용 | 검증 결과 |
|----------------|----------|----------|
| 감각-운동 통합 | Sensory → Circuit → Motor | ✓ 성공 |
| 반사 회로 | Push-Pull, Disinhibition | ✓ 성공 |
| 선천적 본능 | 시냅스 초기 가중치 | ✓ 성공 |
| Fight-or-Flight | Fear ↔ Attack 상호억제 | ✓ 성공 |
| 측면 억제 (WTA) | 경쟁적 의사결정 | ✓ 성공 |

### 1.3 프로젝트의 핵심 원칙

```
"빈 서판은 죽음이다" (Blank Slate = Death)

- 선천적 본능 = 시냅스의 초기 가중치
- if문이 아닌 회로 구조로 행동 결정
- 학습은 기존 회로의 조정이지, 새 규칙의 추가가 아님
```

---

## 2. 진화 경로

### 2.1 버전 히스토리

```
Chrome Dino (졸업)
    │
    ▼
snnTorch Slither (한계 도달)
    │
    ▼
PyGeNN Slither v1~v18 (기초 구축)
    │
    ▼
v19: 음식 추적 + WTA 버그 수정
    │
    ▼
v27: Push-Pull 반사 회로 완성
    │
    ▼
v28c: Baseline 확립 (Best=27, Avg=17)
    │
    ▼
v29~v30: Attack 실험 (실패, 교훈)
    │
    ▼
v31: Disinhibition 발견 (돌파구!)
    │
    ▼
v32c: First Kill 달성
    │
    ▼
v33~v36: R-STDP 실험 (한계 확인)
    │
    ▼
v37f: Defensive Kill 메커니즘 규명
    │
    ▼
v40b: 시간 제한 해제 → 진정한 성능 발현
    │
    ▼
★ 졸업 ★
```

### 2.2 성능 진화

| 버전 | Best | Avg | Kills/ep | 핵심 변화 |
|------|------|-----|----------|----------|
| v19 | 10 | 5 | 0 | 음식 추적 추가 |
| v28c | 27 | 17 | 0 | Push-Pull 완성 |
| v32c | 31 | 18 | 0.04 | First Kill |
| v37f | 30 | 17 | 0.03 | Disinhibition 최적화 |
| **v40b** | **64** | **37.6** | **0.44** | **시간 제한 해제** |

---

## 3. 핵심 발견 및 원칙

### 3.1 생물학적 배선 원칙

#### Push-Pull 반사 (Contralateral Wiring)

```
적이 왼쪽에 있으면 → 오른쪽으로 회전

Enemy_L ──PUSH(+80)──► Motor_R (반대편 활성화)
Enemy_L ──PULL(-60)──► Motor_L (같은편 억제)
```

**생물학적 근거:** 척추동물의 도피 반사. 위협 방향의 반대쪽 근육 활성화.

#### 동측 배선 (Ipsilateral Wiring)

```
음식이 왼쪽에 있으면 → 왼쪽으로 회전

Food_L ──IPSI(+20)──► Motor_L (같은편 활성화)
```

**생물학적 근거:** 접근 행동. 목표 방향으로 이동.

#### 탈억제 (Disinhibition)

```
평소: Fear(억제) → 회피 행동
사냥 시: Hunt → Fear 억제 해제 → 공격 가능

EnemyHead_L ──(-100)──► Motor_R (Fear Push 상쇄)
EnemyHead_L ──(+80)───► Motor_L (Fear Pull 상쇄)
```

**생물학적 근거:** 포식자의 사냥 시 공포 반응 억제. 편도체-전두엽 상호작용.

### 3.2 발견된 버그와 교훈

| 버그 | 원인 | 해결 | 교훈 |
|------|------|------|------|
| WTA 작동 안함 | wMax=0 클리핑 | 실제 억제 가중치 설정 | 파라미터 기본값 확인 |
| 좌우 구분 불가 | cos(-x)=cos(x) | 직접 매핑 사용 | 수학 함수 특성 확인 |
| 스파이크 과다 카운트 | RefracTime > 0 | > threshold 사용 | 뉴런 모델 이해 필수 |
| 83% 원인불명 사망 | max_steps 도달 | timeout 추적 추가 | 종료 조건 명시적 처리 |

### 3.3 실패한 접근법과 교훈

#### v29 Attack Mode (실패)

```
시도: Attack 시 양쪽 모터 동시 활성화
결과: delta=0 → 회피 불가 → 사망률 급증
교훈: 양쪽 동시 활성화는 신호 상쇄
```

#### v34 Aggressive Hunter (실패)

```
시도: Fear 완전 상쇄로 공격성 극대화
결과: 자살 공격 → 100% 사망
교훈: Fear는 생존에 필수, 조절만 가능
```

#### v35 R-STDP (실패)

```
시도: Kill 보상으로 Hunt 시냅스 학습
결과: 학습 미발생
원인: 보상 빈도 0.7% (< 1%), 시간 지연 > τ
교훈: R-STDP는 빈번하고 즉각적인 보상 필요
```

---

## 4. 구현된 뇌 아키텍처

### 4.1 뉴런 구성 (v40b, 13,800 neurons)

```
┌─────────────────────────────────────────────────────────────────┐
│                        SENSORY LAYER                            │
├─────────────────────────────────────────────────────────────────┤
│  Food Eye (L/R)      │ 400 × 2 │ 음식 방향 감지                │
│  Enemy Eye (L/R)     │ 400 × 2 │ 적 body 감지                  │
│  Enemy Head (L/R)    │ 200 × 2 │ 적 head 감지 (사냥 대상)      │
│  Body Eye (L/R)      │ 200 × 2 │ 벽/자기 몸 감지               │
├─────────────────────────────────────────────────────────────────┤
│                        CIRCUIT LAYER                            │
├─────────────────────────────────────────────────────────────────┤
│  Hunger Circuit      │ 1,000   │ 섭식 동기                      │
│  Fear Circuit        │ 1,000   │ 회피 동기                      │
│  Attack Circuit      │ 500     │ 공격 동기                      │
│  Integration         │ 8,000   │ 신호 통합                      │
├─────────────────────────────────────────────────────────────────┤
│                        MOTOR LAYER                              │
├─────────────────────────────────────────────────────────────────┤
│  Motor Left          │ 500     │ 좌회전 출력                    │
│  Motor Right         │ 500     │ 우회전 출력                    │
│  Boost               │ 300     │ 가속 출력                      │
└─────────────────────────────────────────────────────────────────┘
```

### 4.2 시냅스 연결 (선천적 본능)

```python
# Fear (적 회피) - Push-Pull
Enemy_L → Motor_R (+80)   # 반대편 활성화
Enemy_L → Motor_L (-60)   # 같은편 억제

# Hunt (사냥) - 동측
EnemyHead_L → Motor_L (+180)  # 적 머리 추적

# Disinhibition (사냥 시 Fear 상쇄)
EnemyHead_L → Motor_R (-100)  # Fear Push 상쇄
EnemyHead_L → Motor_L (+80)   # Fear Pull 상쇄

# Food (섭식) - 동측
Food_L → Motor_L (+20)  # 음식 추적

# Wall (벽 회피) - Push-Pull
Body_L → Motor_R (+80)  # 벽 회피

# WTA (경쟁적 의사결정)
Motor_L ↔ Motor_R (-3)  # 측면 억제
```

### 4.3 신호 흐름 예시

```
상황: 왼쪽에 적 body와 head가 보임

1. 감각 입력
   Enemy_L = 0.8, EnemyHead_L = 0.6

2. Fear 회로 (회피)
   Motor_R += 0.8 × 80 = +64
   Motor_L += 0.8 × (-60) = -48

3. Hunt 회로 (사냥)
   Motor_L += 0.6 × 180 = +108

4. Disinhibition (Fear 상쇄)
   Motor_R += 0.6 × (-100) = -60
   Motor_L += 0.6 × 80 = +48

5. 최종 결과
   Motor_R = 64 - 60 = +4
   Motor_L = -48 + 108 + 48 = +108

6. 행동: 왼쪽으로 강하게 회전 (사냥!)
```

---

## 5. 생물학적 뇌와의 대응

### 5.1 뇌 영역 매핑

| 구현 요소 | 생물학적 대응 | 기능 |
|----------|--------------|------|
| Sensory Layer | 감각 피질 | 환경 정보 인코딩 |
| Fear Circuit | 편도체 | 위협 감지, 회피 동기 |
| Hunger Circuit | 시상하부 | 섭식 동기 |
| Attack Circuit | 중격핵 | 공격 동기 |
| Motor Layer | 운동 피질 | 행동 출력 |
| WTA | 기저핵 | 행동 선택, 경쟁 |
| Push-Pull | 척수 반사 | 교차 억제 |

### 5.2 검증된 생물학적 원칙

1. **Dale's Law (흥분/억제 분리)**
   - 하나의 뉴런은 흥분 또는 억제 중 하나만 담당
   - 구현: 별도의 흥분/억제 시냅스

2. **Lateral Inhibition (측면 억제)**
   - 경쟁을 통한 명확한 선택
   - 구현: WTA 회로

3. **Disinhibition (탈억제)**
   - 억제의 억제 = 활성화
   - 구현: Hunt → Fear 억제

4. **Contralateral Wiring (교차 배선)**
   - 감각과 운동의 교차 연결
   - 구현: Push-Pull 반사

### 5.3 아직 구현되지 않은 것

| 요소 | 생물학적 역할 | Slither.io에서 불필요한 이유 |
|------|-------------|---------------------------|
| 해마 | 공간 기억 | 매 순간 반사로 충분 |
| 전두엽 | 계획, 억제 | 즉각 행동만 필요 |
| 도파민 시스템 | 학습 신호 | 보상이 너무 희소 |
| 거울 뉴런 | 타자 이해 | 사회적 상호작용 없음 |

---

## 6. 최종 목표를 향한 기여

### 6.1 달성한 것

```
✓ 생물학적 원칙으로만 행동하는 에이전트
✓ if문 없이 회로 구조로 의사결정
✓ 선천적 본능의 시냅스 가중치 표현
✓ Push-Pull, Disinhibition 등 핵심 메커니즘 검증
✓ LIF 뉴런 + STDP 기반 SNN 프레임워크
✓ PyGeNN GPU 가속 파이프라인
```

### 6.2 재사용 가능한 컴포넌트

| 컴포넌트 | 설명 | 다음 단계 활용 |
|----------|------|--------------|
| LIF 뉴런 모델 | 생물학적 스파이킹 뉴런 | 그대로 사용 |
| Push-Pull 회로 | 반사적 회피/접근 | 기본 운동에 적용 |
| WTA 회로 | 경쟁적 선택 | 의사결정에 적용 |
| R-STDP | 보상 기반 학습 | 조건 맞으면 사용 |
| Fear-Attack 억제 | 동기 경쟁 | 정서 시스템 확장 |

### 6.3 얻은 교훈

```
1. 환경이 학습 조건을 결정한다
   - Slither.io: R-STDP 조건 불충족 (보상 희소, 지연)
   - 다음 환경: 빈번하고 즉각적인 보상 필요

2. 선천적 본능 없이는 학습 불가
   - 빈 서판 → 랜덤 행동 → 사망
   - 기본 회로 위에 학습으로 조정

3. 복잡한 행동은 단순한 회로의 조합
   - Push + Pull + Disinhibition = 사냥 행동
   - 새 "모듈" 추가 아닌 기존 회로 조합

4. 측정하지 않으면 개선 불가
   - Death cause 추적으로 병목 발견
   - max_steps 제한이 진짜 문제였음
```

---

## 7. 한계와 미해결 과제

### 7.1 Slither.io 환경의 한계

```
1. 내부 상태 없음
   - 배고픔, 피로, 고통 등 항상성 시스템 부재
   - "느끼는" 것이 아닌 "반응하는" 것만 가능

2. 기억 불필요
   - 매 순간 현재 입력만으로 결정
   - 과거 경험이 미래에 영향 없음

3. 사회적 상호작용 없음
   - 적은 단순 장애물
   - 협력, 의사소통, 공감 불가

4. 시간적 계획 불필요
   - 즉각 반응만으로 생존 가능
   - 지연 보상, 순서 있는 행동 불필요
```

### 7.2 기술적 한계

```
1. Active Kill 불가
   - 환경 구조상 "추격 킬" 불가능
   - Defensive Kill만 가능 (적이 우리에게 충돌)

2. R-STDP 학습 조건 불충족
   - 보상 빈도: 0.7% (필요: > 1%)
   - 시간 지연: > 3초 (필요: < τ)

3. 뉴런 수 제한
   - 13,800 뉴런으로 복잡한 전략 불가
   - 스케일업 시 새로운 행동 가능성
```

---

## 8. 다음 단계 권장사항

### 8.1 Phase 2: 느끼는 뇌 (Affective Brain)

**목표:** 내부 상태와 정서 시스템 구현

**필요 환경 조건:**
- 항상성 시스템 (에너지, 체온, 고통)
- 내부 상태가 행동에 영향
- 빈번한 보상/처벌 신호

**구현 대상:**
- 시상하부: 항상성 조절
- 편도체: 정서적 평가
- 보상 회로: 도파민 시스템

### 8.2 Phase 3: 기억하는 뇌 (Mnemonic Brain)

**목표:** 장기 기억과 공간 인식

**필요 환경 조건:**
- 기억이 생존에 필수인 환경
- 공간 탐색, 장소 기억
- 시간에 따른 변화

**구현 대상:**
- 해마: 공간 기억, 에피소드 기억
- 내후각 피질: 그리드 셀

### 8.3 Phase 4: 계획하는 뇌 (Executive Brain)

**목표:** 계획, 억제, 의사결정

**필요 환경 조건:**
- 지연 보상
- 순서 있는 작업
- 충동 억제 필요

**구현 대상:**
- 전두엽: 실행 기능
- 기저핵: 행동 선택/억제

---

## 9. 결론

### Slither.io 프로젝트의 의의

```
┌─────────────────────────────────────────────────────────────────┐
│                                                                 │
│  "Slither.io는 뇌간을 만드는 연습이었다"                        │
│                                                                 │
│  - 반사하는 뇌의 기본 원칙 검증                                 │
│  - 생물학적 배선의 효과 확인                                    │
│  - 선천적 본능의 중요성 입증                                    │
│  - SNN 프레임워크와 방법론 확립                                 │
│                                                                 │
│  이제 "느끼고, 기억하고, 계획하는" 뇌를 만들 준비가 되었다     │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 최종 성과

| 지표 | 시작 | 최종 (v40b) | 개선 |
|------|------|------------|------|
| Best Length | 10 | 64 | +540% |
| Avg Length | 5 | 37.6 | +652% |
| Kills/ep | 0 | 0.44 | ∞ |
| 생존 시간 | ~200 steps | ~2500 steps | +1150% |

### 졸업 인증

```
╔═══════════════════════════════════════════════════════════════╗
║                                                               ║
║            SLITHER.IO PROJECT - GRADUATED                     ║
║                                                               ║
║  Date: 2025-01-28                                             ║
║  Final Version: v40b                                          ║
║  Status: Phase 1 Complete                                     ║
║                                                               ║
║  "The brain that reacts has been built.                       ║
║   Now, build the brain that feels."                           ║
║                                                               ║
╚═══════════════════════════════════════════════════════════════╝
```

---

## 부록: 파일 구조

```
backend/genesis/
├── slither_pygenn_biological.py  # v40b 최종 버전
├── slither_gym.py                # 훈련 환경
├── checkpoints/
│   └── slither_pygenn_bio/
│       ├── best.npz              # 최고 성능 가중치
│       ├── best_64.npz           # Best=64 체크포인트
│       └── final.npz             # 최종 가중치
└── docs/
    └── SLITHER_GRADUATION.md     # 이 문서
```

---

*Genesis Brain Project - Phase 1 Complete*
*2025-01-28*
