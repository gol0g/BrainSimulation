# Genesis Brain ëª¨ë¸ ë¶„ì„ ë° ì ì¬ì  ë¬¸ì œì  ê²€í† 

## ì‹¤í–‰ ìš”ì•½

í˜„ì¬ Genesis Brain v4.6.2 ëª¨ë¸ì— ëŒ€í•œ ì¢…í•© ë¶„ì„ ê²°ê³¼, **ì‹¬ê°í•œ ë²„ê·¸ëŠ” ë°œê²¬ë˜ì§€ ì•Šì•˜ìœ¼ë‚˜**, ë‹¤ìŒ ì˜ì—­ì—ì„œ ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ë“¤ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤:

1. **ë³µì¡ë„ ê´€ë¦¬** - 10,000+ ì¤„ì˜ ì½”ë“œì—ì„œ ê¸°ëŠ¥ ê°„ ìƒí˜¸ì˜ì¡´ì„±ì´ ë†’ìŒ
2. **ìˆ˜í•™ì  ì •í™•ì„±** - ì¼ë¶€ ê·¼ì‚¬ê°’ê³¼ í•˜ë“œì½”ë”©ëœ ìƒìˆ˜ë“¤
3. **ë©”ëª¨ë¦¬ ê´€ë¦¬** - ë¬´ì œí•œ íˆìŠ¤í† ë¦¬ ì¶•ì  ê°€ëŠ¥ì„±
4. **Drift ì ì‘** - ì¼ë¶€ ì—£ì§€ ì¼€ì´ìŠ¤ì—ì„œ ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŒ
5. **í…ŒìŠ¤íŠ¸ ë¶€ì¬** - ìë™í™”ëœ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ê°€ ì—†ìŒ

---

## 1. ì•„í‚¤í…ì²˜ ë° ë³µì¡ë„ ë¶„ì„

### 1.1 ì „ì²´ êµ¬ì¡°

**í˜„ì¬ ìƒíƒœ:**
- **ì´ ì½”ë“œ ë¼ì¸ ìˆ˜**: ~10,157 ì¤„ (genesis ëª¨ë“ˆë§Œ)
- **í•µì‹¬ ëª¨ë“ˆ**: 20ê°œ
- **ì£¼ìš” ì˜ì¡´ì„± ì²´ì¸**: Agent â†’ ActionSelector â†’ Memory/Regret/Uncertainty â†’ Hierarchy

**ë¬¸ì œì :**
```
ActionSelector í´ë˜ìŠ¤ê°€ ë„ˆë¬´ ë§ì€ ì±…ì„ì„ ê°€ì§:
- í–‰ë™ ì„ íƒ (G ê³„ì‚°)
- ì „ì´ ëª¨ë¸ í•™ìŠµ
- ë©”ëª¨ë¦¬ ê´€ë¦¬
- í›„íšŒ ê³„ì‚°
- ë¶ˆí™•ì‹¤ì„± ì¶”ì 
- ê³„ì¸µì  ì»¨íŠ¸ë¡¤
- THINK ë©”íƒ€ì¸ì§€
- Temporal rollout
- Drift ê°ì§€/ì–µì œ
```

**ê¶Œì¥ì‚¬í•­:**
- **Single Responsibility Principle ìœ„ë°˜**: `ActionSelector`ë¥¼ ë” ì‘ì€ í´ë˜ìŠ¤ë“¤ë¡œ ë¶„í•´
  - `TransitionLearner` (ì „ì´ ëª¨ë¸ í•™ìŠµ)
  - `MemoryIntegrator` (ë©”ëª¨ë¦¬ í†µí•©)
  - `UncertaintyManager` (ë¶ˆí™•ì‹¤ì„± ê´€ë¦¬)
  - `ActionSelector` (ìˆœìˆ˜ G ê³„ì‚° ë° í–‰ë™ ì„ íƒë§Œ)

### 1.2 ìˆœí™˜ ì˜ì¡´ì„± ìœ„í—˜

**ë°œê²¬ëœ íŒ¨í„´:**
```python
ActionSelector
  â”œâ”€> CounterfactualEngine (regret ê³„ì‚°)
  â”‚    â””â”€> action_selector.transition_model ì ‘ê·¼ (ìˆœí™˜)
  â”œâ”€> LTMStore (ê¸°ì–µ ì €ì¥/íšŒìƒ)
  â”‚    â””â”€> action_selector.uncertainty ì ‘ê·¼ (ìˆœí™˜)
  â””â”€> UncertaintyTracker
       â””â”€> action_selector.transition_model ì ‘ê·¼ (ìˆœí™˜)
```

**ìœ„í—˜ë„**: ì¤‘ê°„
- í˜„ì¬ëŠ” ë©”ì„œë“œ í˜¸ì¶œë¡œ í•´ê²°ë˜ì–´ ìˆìœ¼ë‚˜, í…ŒìŠ¤íŠ¸ë‚˜ ë¦¬íŒ©í† ë§ ì‹œ ë¬¸ì œ ë°œìƒ ê°€ëŠ¥

**ê¶Œì¥ì‚¬í•­:**
- Dependency Injection íŒ¨í„´ ì‚¬ìš©
- ì¸í„°í˜ì´ìŠ¤ ë¶„ë¦¬ (ê³µìœ  ë°ì´í„°ëŠ” ë³„ë„ `ModelState` ê°ì²´ë¡œ)

---

## 2. ìˆ˜í•™ì  ì •í™•ì„± ë° ì•ˆì •ì„±

### 2.1 KL Divergence ê³„ì‚°

**ìœ„ì¹˜**: `preference_distributions.py`

**ì ì¬ì  ë¬¸ì œ:**
```python
# Beta ë¶„í¬ KL ê³„ì‚°
kl = (alpha1 - alpha0) * (psi(alpha1) - psi(alpha1 + beta1)) + ...
```

**ë¬¸ì œì :**
1. **ìˆ˜ì¹˜ ì•ˆì •ì„±**: Î±, Î²ê°€ ë§¤ìš° ì‘ê±°ë‚˜ í´ ë•Œ `psi()` (digamma) í•¨ìˆ˜ê°€ ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŒ
2. **ê²½ê³„ ì¼€ì´ìŠ¤**: ê´€ì¸¡ê°’ì´ 0 ë˜ëŠ” 1ì¼ ë•Œ Beta ë¶„í¬ í‰ê°€ì—ì„œ `-inf` ë°œìƒ ê°€ëŠ¥
3. **í´ë¦¬í•‘ íš¨ê³¼**: `np.clip(obs, 0.001, 0.999)`ë¡œ ê·¹ë‹¨ê°’ ë°©ì§€í•˜ì§€ë§Œ, ì´ê²Œ ì •ë³´ ì†ì‹¤ ìœ ë°œ

**ê¶Œì¥ì‚¬í•­:**
```python
# ì•ˆì „í•œ í´ë¦¬í•‘ ë° ë¡œê·¸ ê³µê°„ ê³„ì‚°
obs_safe = np.clip(obs, 1e-6, 1 - 1e-6)
log_prob = (alpha - 1) * np.log(obs_safe) + (beta - 1) * np.log(1 - obs_safe)
# ì˜¤ë²„í”Œë¡œìš° ì²´í¬
if np.isnan(log_prob) or np.isinf(log_prob):
    log_prob = -10.0  # fallback
```

### 2.2 ì „ì´ ëª¨ë¸ í•™ìŠµ

**ìœ„ì¹˜**: `action_selection.py:1600-1700`

**ë¬¸ì œì :**
```python
# í•™ìŠµë¥ ì´ ê³ ì •ë¨
self.transition_lr = 0.1

# ì¹´ìš´íŠ¸ ê¸°ë°˜ ì ì‘ì´ ì—†ìŒ
delta_mean[a] += lr * (delta_actual - delta_mean[a])
```

**ìœ„í—˜:**
- ì´ˆê¸° ì˜ëª»ëœ ê²½í—˜ì´ ì˜¤ë˜ ì§€ì†ë¨
- Drift í›„ ì¬í•™ìŠµì´ ëŠë¦¼
- ê³ ì • learning rateëŠ” exploration-exploitation ê· í˜• ë¶€ì¡±

**ê¶Œì¥ì‚¬í•­:**
```python
# ì ì‘ì  í•™ìŠµë¥ 
adaptive_lr = self.transition_lr / (1 + 0.1 * count[a])
# ë˜ëŠ” uncertainty ê¸°ë°˜
adaptive_lr = self.transition_lr * (1 + transition_std[a])
```

### 2.3 Softmax ì˜¨ë„

**ìœ„ì¹˜**: `action_selection.py:149`

**í˜„ì¬:**
```python
self.temperature = 0.3  # ê³ ì •ê°’
```

**ë¬¸ì œì :**
- ë„ˆë¬´ ë‚®ìœ¼ë©´ â†’ íƒìƒ‰ ë¶€ì¡±, êµ­ì†Œ ìµœì í•´ ê³ ì°©
- ë„ˆë¬´ ë†’ìœ¼ë©´ â†’ ëœë¤ í–‰ë™, í•™ìŠµ ëŠë¦¼
- ìƒí™©ì— ë”°ë¼ ì¡°ì ˆ í•„ìš” (ì´ˆê¸° íƒìƒ‰ vs í›„ê¸° í™œìš©)

**ê¶Œì¥ì‚¬í•­:**
```python
# Uncertainty ê¸°ë°˜ ì˜¨ë„ ì¡°ì ˆ
temperature = 0.1 + 0.5 * global_uncertainty
# ë˜ëŠ” ì‹œê°„ ê¸°ë°˜ ëƒ‰ê°
temperature = max(0.1, 0.5 * np.exp(-step / 1000))
```

---

## 3. ë©”ëª¨ë¦¬ ë° ì„±ëŠ¥ ì´ìŠˆ

### 3.1 ë¬´ì œí•œ íˆìŠ¤í† ë¦¬ ì¶•ì 

**ë¬¸ì œ ìœ„ì¹˜:**

1. **Regret íˆìŠ¤í† ë¦¬** (`regret.py:54`)
```python
recent_regret: List[float] = field(default_factory=list)
history_size: int = 50  # ì œí•œ ìˆìŒ (OK)
```

2. **F íˆìŠ¤í† ë¦¬** (`agent.py:112-113`)
```python
self._F_history = []  # ì œí•œ: 100 (OK)
```

3. **Surprise íˆìŠ¤í† ë¦¬** (`uncertainty.py:156`)
```python
self._surprise_history = []  # ì œí•œ: 100 (OK)
```

4. **LTM Episodes** (`memory.py:144`)
```python
self.episodes: List[Episode] = []  # max_episodes=1000ìœ¼ë¡œ ì œí•œë¨ (OK)
```

**ì¢‹ì€ ì **: ëŒ€ë¶€ë¶„ì˜ íˆìŠ¤í† ë¦¬ê°€ ìµœëŒ€ í¬ê¸° ì œí•œ ìˆìŒ

**ì ì¬ì  ë¬¸ì œ:**
- `_action_history` (`action_selection.py:157`) - **ì œí•œ ì—†ìŒ**
- `_entropy_history` (`action_selection.py:138`) - **ì œí•œ: 100** (OK)

**ê¶Œì¥ì‚¬í•­:**
```python
# action_historyì— ì œí•œ ì¶”ê°€
if len(self._action_history) > 1000:
    self._action_history.pop(0)
```

### 3.2 Context-weighted Transition ë©”ëª¨ë¦¬

**ìœ„ì¹˜**: `action_selection.py:184-200`

**ë¬¸ì œ:**
```python
# HierarchicalControllerê°€ contextë³„ ì „ì´ ëª¨ë¸ì„ ì €ì¥
# K=4 contexts Ã— 5 actions Ã— 8 observations = 160 entries
# ê° entry: delta_mean + delta_std = 2 arrays
# ë©”ëª¨ë¦¬: ~2.5KB (ë§¤ìš° ì‘ìŒ, ë¬¸ì œ ì—†ìŒ)
```

**í‰ê°€**: ê´œì°®ìŒ

### 3.3 ê³„ì‚° ë³µì¡ë„

**THINK í–‰ë™ ì„ íƒ ì‹œ:**
```python
# compute_G_think() â†’ rollout ì‹¤í–‰
for sample in range(think_rollout_samples):  # 1íšŒ
    for horizon in range(think_rollout_horizon):  # 2 steps
        for action in range(n_physical_actions):  # 5 actions
            # G ê³„ì‚°
```

**ë³µì¡ë„**: O(1 Ã— 2 Ã— 5) = O(10) - ê´œì°®ìŒ

**Temporal Rollout ì‹œ:**
```python
for sample in range(rollout_n_samples):  # 3íšŒ
    for horizon in range(rollout_horizon):  # 3 steps
        for action in range(n_actions):  # 5-6 actions
            # G ê³„ì‚°
```

**ë³µì¡ë„**: O(3 Ã— 3 Ã— 6) = O(54) - í—ˆìš© ê°€ëŠ¥

**ê¶Œì¥ì‚¬í•­**: í˜„ì¬ ë³µì¡ë„ëŠ” ì‹¤ì‹œê°„ ì œì–´ì— ì í•©í•¨

---

## 4. Free Energy Principle ì¼ê´€ì„± ê²€ì¦

### 4.1 G = Risk + Ambiguity + Complexity ê³µì‹

**ì´ë¡ ì  ì •ì˜:**
```
G(a) = E_Q(s'|a)[ KL[Q(o|s') || P(o)] ]  # Pragmatic value (Risk)
     + E_Q(s'|a)[ H[P(o|s')] ]            # Epistemic value (Ambiguity)
     + KL[Q(s'|a) || P(s')]               # Complexity
```

**í˜„ì¬ êµ¬í˜„** (`action_selection.py:540-700`):

âœ… **Risk ê³„ì‚° (ì˜¬ë°”ë¦„)**:
```python
risk = sum(preferences.kl_divergence(obs_component, predicted_obs[i]))
```

âœ… **Ambiguity ê³„ì‚° (ê·¼ì‚¬)**:
```python
ambiguity = mean(delta_std) * 1.5  # ê°„ì ‘ ì¸¡ì •
```
- **ë¬¸ì œ**: ì§„ì§œ H[P(o|s')]ëŠ” ì˜ˆì¸¡ ë¶„í¬ì˜ ì—”íŠ¸ë¡œí”¼ì¸ë°, stdë¡œë§Œ ê·¼ì‚¬
- **ì˜í–¥**: ë°©í–¥ì€ ë§ì§€ë§Œ ìŠ¤ì¼€ì¼ì´ ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ

âš ï¸ **Complexity ê³„ì‚° (ì˜ë¬¸)**:
```python
complexity = KL[Q(s'|a) || P(s')]
```
- **ë¬¸ì œ**: `P(s')`ê°€ ëª…í™•íˆ ì •ì˜ë˜ì§€ ì•ŠìŒ
- **í˜„ì¬**: `StatePreferenceDistribution`ë¡œ ë‚´ë¶€ ìƒíƒœ (energy, pain) ì„ í˜¸ ì‚¬ìš©
- **ì´ë¡ ê³¼ ì°¨ì´**: FEPì—ì„œ P(s')ëŠ” prior beliefì¸ë°, ì—¬ê¸°ì„œëŠ” preferred stateë¡œ ì‚¬ìš©

**í‰ê°€**: ì´ë¡ ì ìœ¼ë¡œ "FEP-inspired"ì´ì§€ "True FEP"ëŠ” ì•„ë‹˜

**ê¶Œì¥ì‚¬í•­:**
1. Ambiguityë¥¼ ì‹¤ì œ ì—”íŠ¸ë¡œí”¼ë¡œ ê³„ì‚° (ê°€ëŠ¥í•˜ë©´)
2. Complexity ì •ì˜ë¥¼ ëª…í™•íˆ ë¬¸ì„œí™” ("ìš°ë¦¬ëŠ” P(s')ë¥¼ ì´ë ‡ê²Œ ì •ì˜í•œë‹¤")

### 4.2 Inference (Perception)

**ìœ„ì¹˜**: `inference.py:35-80`

**ì´ë¡ **:
```
Q(s) âˆ P(o|s) * P(s)  (ë² ì´ì¦ˆ ì¶”ë¡ )
```

**êµ¬í˜„**:
```python
# Likelihood: P(o|s)
log_likelihood = model.likelihood(obs, s)
# Prior: P(s) = Q_prev (í˜„ì¬ belief)
Q_new = softmax(log_likelihood + log(Q_prev))
```

âœ… **í‰ê°€**: ì˜¬ë°”ë¥¸ ë² ì´ì¦ˆ ì¶”ë¡ 

**ë¯¸ì„¸ ë¬¸ì œ**:
- ë°˜ë³µ íšŸìˆ˜ ê³ ì • (iterations=5)
- ìˆ˜ë ´ ì²´í¬ ì—†ìŒ â†’ ë¶ˆí•„ìš”í•œ ê³„ì‚° ë˜ëŠ” ì¡°ê¸° ì¢…ë£Œ

**ê¶Œì¥ì‚¬í•­:**
```python
for i in range(max_iterations):
    Q_new = bayesian_update(...)
    if kl_divergence(Q_new, Q_old) < tolerance:
        break  # ìˆ˜ë ´
```

---

## 5. Drift ì ì‘ ë©”ì»¤ë‹ˆì¦˜ ì•ˆì •ì„±

### 5.1 Drift Suppression (v4.6.1)

**ìœ„ì¹˜**: `action_selection.py:1938-2030`

**ì›ë¦¬**:
```python
# Transition error spike ê°ì§€
if prediction_error > baseline * 2.5:
    suppression_factor *= 0.5  # recall weight ì ˆë°˜
# ì ì§„ì  íšŒë³µ
suppression_factor += recovery_rate
```

**ì ì¬ì  ë¬¸ì œ:**

1. **False Positive**: ì •ìƒì ì¸ surpriseë„ driftë¡œ ì˜¤ì¸ ê°€ëŠ¥
   - ì˜ˆ: ìƒˆë¡œìš´ ìŒì‹ ìœ„ì¹˜
   - ê²°ê³¼: ìœ ìš©í•œ ê¸°ì–µë„ ì–µì œë¨

2. **Threshold ë¯¼ê°ë„**: `2.5 Ã— baseline`ì€ ì„ì˜ê°’
   - ë„ˆë¬´ ë‚®ìœ¼ë©´: ìì£¼ ì–µì œ (ê³¼ë¯¼ë°˜ì‘)
   - ë„ˆë¬´ ë†’ìœ¼ë©´: drift ë†“ì¹¨ (ë‘”ê°)

3. **Regretì™€ Suppression ê²½ìŸ** (v4.6.2):
```python
# regret spikeë„ ì–µì œ ì‹ í˜¸ë¡œ ì‚¬ìš©
if regret > regret_baseline * 2.0:
    suppression_factor *= 0.7
```
   - **ìœ„í—˜**: regret spikeëŠ” "ë‚˜ìœ ì„ íƒ"ì¼ ë¿, driftì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
   - ì˜ˆ: ë‹¨ìˆœíˆ ìœ„í—˜ì— ì ‘ê·¼í•œ ê²½ìš° â†’ ì–µì œ ë¶ˆí•„ìš”

**ê¶Œì¥ì‚¬í•­:**
- Drift ê°ì§€ì— ì—¬ëŸ¬ ì‹ í˜¸ ì¡°í•©:
  - Transition error AND
  - Context entropy ì¦ê°€ AND
  - Regret spike
- ë‹¨ì¼ ì‹ í˜¸ë§Œìœ¼ë¡œ ì–µì œí•˜ì§€ ë§ ê²ƒ

### 5.2 Regime-based Memory (v4.7 ê³„íš)

**ìœ„ì¹˜**: `action_selection.py:271-279`

**ì•„ì´ë””ì–´**: ë ˆì§ë³„ë¡œ ë©”ëª¨ë¦¬ ë¶„ë¦¬ (pre-drift vs post-drift)

**í˜„ì¬ ìƒíƒœ**: ì½”ë“œì— êµ¬ì¡°ëŠ” ìˆìœ¼ë‚˜ **ë¯¸ì™„ì„±**
```python
self.regime_ltm: Optional[RegimeLTMStore] = None
self.regime_memory_enabled = False  # ê¸°ë³¸ ë¹„í™œì„±í™”
```

**ë¬¸ì œ**: 
- Regime ê°ì§€ ë¡œì§ (`regime.py`)ì€ ìˆìœ¼ë‚˜ í†µí•© ì•ˆ ë¨
- `RegimeLTMStore`ê°€ ì‹¤ì œë¡œ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ

**ê¶Œì¥ì‚¬í•­:**
- v4.7 ì™„ì„±í•˜ê±°ë‚˜
- Drift suppressionìœ¼ë¡œ ì¶©ë¶„í•œì§€ ê²€ì¦ í›„ ë ˆì§ ê¸°ë°˜ ë©”ëª¨ë¦¬ ì œê±°

---

## 6. ë³´ì•ˆ ë° ì•ˆì •ì„±

### 6.1 NumPy ê²½ê³  ë° ì˜¤ë²„í”Œë¡œìš°

**ì ì¬ì  ë¬¸ì œ:**
```python
# ë¡œê·¸ ê³µê°„ ê³„ì‚°ì—ì„œ -inf ê°€ëŠ¥
log_prob = np.log(obs)  # obs=0ì´ë©´ -inf
kl = np.sum(...)  # inf ì „íŒŒ
```

**í˜„ì¬ ë°©ì–´:**
- `np.clip(obs, 0.001, 0.999)` (ëŒ€ë¶€ë¶„ì˜ ìœ„ì¹˜ì—ì„œ)
- `eps=1e-10` ì¶”ê°€ (ì¼ë¶€ ìœ„ì¹˜ì—ì„œ)

**ê°œì„  í•„ìš” ìœ„ì¹˜:**
1. `preference_distributions.py:120-160` - Beta ë¶„í¬ í‰ê°€
2. `action_selection.py:540-800` - G ê³„ì‚°
3. `inference.py:60-80` - ë² ì´ì¦ˆ ì—…ë°ì´íŠ¸

**ê¶Œì¥ì‚¬í•­:**
```python
# ëª¨ë“  ë¡œê·¸ ê³„ì‚° ì „
def safe_log(x, eps=1e-10):
    return np.log(np.clip(x, eps, None))

# ëª¨ë“  ë‚˜ëˆ—ì…ˆ ì „
def safe_divide(a, b, eps=1e-10):
    return a / (b + eps)
```

### 6.2 Random Seed ê´€ë¦¬

**ìœ„ì¹˜**: `reproducibility.py`

âœ… **ì¢‹ì€ ì **: ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ê´€ë¦¬ ì‹œìŠ¤í…œ ìˆìŒ

**ë¬¸ì œì **: 
```python
# ê¸€ë¡œë²Œ ì‹œë“œë§Œ ì„¤ì •
np.random.seed(seed)
```
- PyTorch, TensorFlow ë“± ë‹¤ë¥¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‹œë“œ ë¯¸ì„¤ì •
- ë©€í‹°ìŠ¤ë ˆë”© í™˜ê²½ì—ì„œ ì¬í˜„ì„± ë³´ì¥ ì•ˆ ë¨

**í˜„ì¬ ì˜í–¥**: ì—†ìŒ (NumPyë§Œ ì‚¬ìš©)

**ë¯¸ë˜ ëŒ€ë¹„ ê¶Œì¥ì‚¬í•­:**
```python
def set_all_seeds(seed):
    np.random.seed(seed)
    random.seed(seed)  # Python random ëª¨ë“ˆ
    # í–¥í›„ ì¶”ê°€:
    # torch.manual_seed(seed)
    # tf.random.set_seed(seed)
```

---

## 7. í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€

### 7.1 í˜„ì¬ ìƒíƒœ

**ë°œê²¬ë¨**:
- âŒ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì—†ìŒ
- âŒ í†µí•© í…ŒìŠ¤íŠ¸ ì—†ìŒ
- âœ… ì¬í˜„ì„± í…ŒìŠ¤íŠ¸ (`reproducibility.py:50-100`)
- âœ… Ablation framework (`ablation.py`)
- âœ… Scenario í…ŒìŠ¤íŠ¸ (`scenarios.py`)

**ë¬¸ì œì **:
- ë¦¬íŒ©í† ë§ ì‹œ íšŒê·€ ê°ì§€ ë¶ˆê°€
- ì—£ì§€ ì¼€ì´ìŠ¤ ê²€ì¦ ì–´ë ¤ì›€
- ìˆ˜í•™ì  ì •í™•ì„± ë³´ì¥ ì•ˆ ë¨

### 7.2 ê¶Œì¥ í…ŒìŠ¤íŠ¸ ëª©ë¡

**1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (Unit Tests)**
```python
# test_preference_distributions.py
def test_beta_kl_divergence_symmetry():
    # KL(P||Q) != KL(Q||P) ê²€ì¦
    
def test_beta_kl_non_negative():
    # KL >= 0 í•­ìƒ ì„±ë¦½
    
def test_extreme_observations():
    # obs=0, obs=1ì¼ ë•Œ ì•ˆì •ì„±

# test_action_selection.py
def test_G_decomposition_non_negative():
    # Risk, Ambiguity, Complexity >= 0

def test_action_probabilities_sum_to_one():
    # Softmax ì •ê·œí™” ê²€ì¦
```

**2. í†µí•© í…ŒìŠ¤íŠ¸ (Integration Tests)**
```python
# test_drift_adaptation.py
def test_rotate_drift_recovery():
    # íšŒì „ drift í›„ N ìŠ¤í… ë‚´ íšŒë³µ í™•ì¸
    
def test_memory_helps_adaptation():
    # LTM í™œì„±í™” ì‹œ ì ì‘ ë¹ ë¥¸ì§€ ê²€ì¦
```

**3. ì†ì„± ê¸°ë°˜ í…ŒìŠ¤íŠ¸ (Property-based)**
```python
# test_properties.py
@hypothesis.given(obs=st.floats(0, 1, width=32))
def test_F_decreases_with_inference(obs):
    # ì¶”ë¡  í›„ Fê°€ ê°ì†Œí•˜ê±°ë‚˜ ìœ ì§€ë˜ëŠ”ì§€
```

---

## 8. ì½”ë“œ í’ˆì§ˆ ë° ìœ ì§€ë³´ìˆ˜ì„±

### 8.1 ë§¤ì§ ë„˜ë²„ (Magic Numbers)

**ë°œê²¬ëœ í•˜ë“œì½”ë”© ìƒìˆ˜ë“¤:**

```python
# action_selection.py
self.temperature = 0.3
self.complexity_weight = 0.5
self.transition_lr = 0.1
self.think_entropy_threshold = 1.0
self.think_G_spread_threshold = 0.1

# preference_distributions.py
alpha_energy = 3.0, beta_energy = 2.0
alpha_pain = 1.0, beta_pain = 5.0

# memory.py
max_episodes = 1000
store_threshold = 0.5
similarity_threshold = 0.95

# uncertainty.py
belief_weight = 0.25
action_weight = 0.30
```

**ë¬¸ì œ**: 
- ê°’ì˜ ê·¼ê±° ë¶ˆëª…í™•
- íŠœë‹ ì–´ë ¤ì›€
- ë„ë©”ì¸ ë³€ê²½ ì‹œ ì¬ì„¤ì • í•„ìš”

**ê¶Œì¥ì‚¬í•­:**
```python
# config.py ë˜ëŠ” dataclass ì‚¬ìš©
@dataclass
class GenesisConfig:
    """ëª¨ë“  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ í•œ ê³³ì—"""
    temperature: float = 0.3
    complexity_weight: float = 0.5
    transition_lr: float = 0.1
    # ... ë‚˜ë¨¸ì§€ íŒŒë¼ë¯¸í„°
    
    @classmethod
    def from_file(cls, path: str):
        """YAML/JSONì—ì„œ ë¡œë“œ"""
```

### 8.2 ì£¼ì„ ë° ë¬¸ì„œí™”

âœ… **ì¢‹ì€ ì **:
- Docstringì´ ëŒ€ë¶€ë¶„ ìˆìŒ
- ìˆ˜í•™ ê³µì‹ì´ ì£¼ì„ìœ¼ë¡œ ì„¤ëª…ë¨
- ë²„ì „ë³„ ë³€ê²½ì‚¬í•­ ê¸°ë¡ë¨

âš ï¸ **ê°œì„  í•„ìš”**:
- ì¼ë¶€ ë³µì¡í•œ ë¡œì§ì— ì£¼ì„ ë¶€ì¡±
- íƒ€ì… íŒíŠ¸ê°€ ì¼ê´€ë˜ì§€ ì•ŠìŒ
- í•¨ìˆ˜ ë°˜í™˜ê°’ ì„¤ëª… ë¶€ì¡±

**ì˜ˆì‹œ (ê°œì„  ì „)**:
```python
def compute_G(self, Q_s=None, current_obs=None):
    # G ê³„ì‚°
    ...
```

**ì˜ˆì‹œ (ê°œì„  í›„)**:
```python
def compute_G(
    self, 
    Q_s: Optional[np.ndarray] = None, 
    current_obs: Optional[np.ndarray] = None
) -> Dict[int, GDecomposition]:
    """
    Expected Free Energy G(a) ê³„ì‚°.
    
    Args:
        Q_s: Belief over states (n_states,). Noneì´ë©´ self.model.Q_s ì‚¬ìš©.
        current_obs: Current observation (8,). Noneì´ë©´ ì „ì´ ëª¨ë¸ë§Œ ì‚¬ìš©.
        
    Returns:
        ê° í–‰ë™ì— ëŒ€í•œ G ë¶„í•´ ë”•ì…”ë„ˆë¦¬.
        
    Raises:
        ValueError: current_obs ì°¨ì›ì´ 8ì´ ì•„ë‹ ë•Œ.
    """
```

---

## 9. íŠ¹ì • ë²„ê·¸ ë° ë²„ê·¸ ê°€ëŠ¥ì„±

### 9.1 Context-weighted Delta Clipping

**ìœ„ì¹˜**: `action_selection.py:2153-2170`

```python
# delta_ctxë¥¼ [-0.05, +0.05]ë¡œ ì œí•œ
delta_ctx = np.clip(delta_ctx, -self.delta_ctx_clamp, self.delta_ctx_clamp)

# ê·¸ í›„ ë¸”ë Œë”©
delta_combined = (1 - alpha_eff) * delta_base + alpha_eff * delta_ctx
```

**ì ì¬ì  ë¬¸ì œ**:
- `delta_ctx`ê°€ í´ë¦¬í•‘ë˜ì§€ë§Œ, ë¸”ë Œë”© í›„ ë‹¤ì‹œ ì»¤ì§ˆ ìˆ˜ ìˆìŒ
- `alpha_eff > 0.5`ì´ê³  `delta_base`ë„ í¬ë©´ í´ë¦¬í•‘ íš¨ê³¼ ìƒì‡„

**ì˜í–¥**: ë‚®ìŒ (alpha ì¼ë°˜ì ìœ¼ë¡œ 0.1-0.2)

**ê¶Œì¥ì‚¬í•­**:
```python
# ë¸”ë Œë”© í›„ ë‹¤ì‹œ í´ë¦¬í•‘
delta_combined = np.clip(delta_combined, -0.1, 0.1)
```

### 9.2 Regret Baseline ì´ˆê¸°í™”

**ìœ„ì¹˜**: `regret.py:88`

```python
if len(self.recent_regret) >= 10:
    self.regret_baseline = np.mean(self.recent_regret[-20:])
```

**ë²„ê·¸**: `recent_regret` ê¸¸ì´ê°€ 10ì´ë©´ `[-20:]`ì€ ì „ì²´ 10ê°œë§Œ ë°˜í™˜
- ì˜ë„: ìµœê·¼ 20ê°œ
- ì‹¤ì œ: 10ê°œ (10 < 20ì´ë¯€ë¡œ)

**ì˜í–¥**: ë‚®ìŒ (í‰ê· ì´ë¯€ë¡œ í° ì°¨ì´ ì—†ìŒ)

**ê¶Œì¥ì‚¬í•­**:
```python
if len(self.recent_regret) >= 20:
    self.regret_baseline = np.mean(self.recent_regret[-20:])
else:
    self.regret_baseline = np.mean(self.recent_regret)  # ì „ì²´ í‰ê· 
```

### 9.3 THINK ì¿¨ë‹¤ìš´ ë²„ê·¸ ê°€ëŠ¥ì„±

**ìœ„ì¹˜**: `action_selection.py:1390-1410`

```python
if self._think_cooldown_counter > 0:
    self._think_cooldown_counter -= 1
    return None  # THINK í‰ê°€ ìŠ¤í‚µ

# ...THINK ì„ íƒë¨
if selected_action == self.THINK_ACTION:
    self._think_cooldown_counter = self.think_cooldown
```

**ë¬¸ì œ**: ì¿¨ë‹¤ìš´ ì¤‘ì—ë„ ë‹¤ë¥¸ ì•¡ì…˜ë“¤ì€ THINKë¥¼ Gì— í¬í•¨í•  ìˆ˜ ìˆìŒ
- `compute_G()`ëŠ” ì¿¨ë‹¤ìš´ê³¼ ë¬´ê´€í•˜ê²Œ THINKì˜ G ê³„ì‚°
- `select_action()`ì—ì„œë§Œ THINK ì œì™¸

**ë²„ê·¸ ê°€ëŠ¥ì„±**: ë‚®ìŒ (ì„¤ê³„ ì˜ë„ì¼ ìˆ˜ ìˆìŒ)

**ëª…í™•í™” í•„ìš”**: ì£¼ì„ìœ¼ë¡œ ì˜ë„ ì„¤ëª…

---

## 10. ì„±ëŠ¥ ìµœì í™” ê¸°íšŒ

### 10.1 ë²¡í„°í™” ê¸°íšŒ

**í˜„ì¬ (ë£¨í”„)**:
```python
# action_selection.py:550-700
for a in range(n_physical):
    # ê° í–‰ë™ë§ˆë‹¤ G ê³„ì‚°
    risk = ...
    ambiguity = ...
```

**ìµœì í™” (ë²¡í„°í™”)**:
```python
# ëª¨ë“  í–‰ë™ì„ í•œ ë²ˆì— ê³„ì‚°
actions = np.arange(n_physical)
deltas = self.transition_model['delta_mean'][actions]  # (5, 8)
predicted_obs = current_obs[None, :] + deltas  # (5, 8)
risks = self.preferences.kl_divergence_batch(predicted_obs)  # (5,)
```

**ì˜ˆìƒ ê°œì„ **: 2-3ë°° ì†ë„ í–¥ìƒ

### 10.2 ìºì‹± ê¸°íšŒ

**í˜„ì¬ ë¬¸ì œ**:
```python
# ê°™ì€ Q_sì— ëŒ€í•´ ì—¬ëŸ¬ ë²ˆ G ê³„ì‚°
G_decomp = compute_G(Q_s)  # 5ê°œ í–‰ë™
G_think = compute_G_think(Q_s)  # ë‚´ë¶€ì—ì„œ ë˜ compute_G í˜¸ì¶œ
```

**ìµœì í™”**:
```python
@lru_cache(maxsize=128)
def compute_G_cached(Q_s_tuple, obs_tuple):
    # Q_sì™€ obsê°€ ê°™ìœ¼ë©´ ìºì‹œëœ ê²°ê³¼ ë°˜í™˜
```

**ì˜ˆìƒ ê°œì„ **: THINK ì‚¬ìš© ì‹œ ~30% ì†ë„ í–¥ìƒ

---

## 11. ìµœì¢… í‰ê°€ ë° ìš°ì„ ìˆœìœ„

### 11.1 ì‹¬ê°ë„ ë¶„ë¥˜

| ì‹¬ê°ë„ | í•­ëª© | ê°œìˆ˜ |
|--------|------|------|
| ğŸ”´ Critical | ì‹¬ê°í•œ ë²„ê·¸ | 0 |
| ğŸŸ  High | ì•ˆì •ì„±/ì •í™•ì„± ë¬¸ì œ | 3 |
| ğŸŸ¡ Medium | ì„±ëŠ¥/ìœ ì§€ë³´ìˆ˜ ë¬¸ì œ | 7 |
| ğŸŸ¢ Low | ê°œì„  ê¸°íšŒ | 10+ |

### 11.2 High Priority ì´ìŠˆ

1. **ìˆ˜ì¹˜ ì•ˆì •ì„± (ìˆ˜í•™)**
   - Beta ë¶„í¬ KLì—ì„œ ê·¹ë‹¨ê°’ ì²˜ë¦¬
   - ë¡œê·¸ ê³µê°„ ê³„ì‚° ì•ˆì „ì¥ì¹˜
   - **ìœ„í—˜**: ëŸ°íƒ€ì„ NaN/Inf ë°œìƒ ê°€ëŠ¥

2. **Drift ê°ì§€ False Positive**
   - Suppression threshold ë¯¼ê°ë„
   - Regret spikeë¥¼ drift ì‹ í˜¸ë¡œ ì‚¬ìš©í•˜ëŠ” ë¡œì§
   - **ìœ„í—˜**: ì •ìƒ í•™ìŠµ ë°©í•´

3. **í…ŒìŠ¤íŠ¸ ì¸í”„ë¼ ë¶€ì¬**
   - íšŒê·€ ê°ì§€ ë¶ˆê°€
   - ìˆ˜í•™ì  ì •í™•ì„± ë¯¸ê²€ì¦
   - **ìœ„í—˜**: í–¥í›„ ë¦¬íŒ©í† ë§ ì‹œ ë²„ê·¸ ìœ ì…

### 11.3 ê¶Œì¥ ì¡°ì¹˜ ìš°ì„ ìˆœìœ„

**Phase 1 (ì¦‰ì‹œ):**
1. âœ… ìˆ˜ì¹˜ ì•ˆì •ì„± ê°œì„  (`safe_log`, `safe_divide` ìœ í‹¸ë¦¬í‹°)
2. âœ… Drift suppression threshold ê²€ì¦ (ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸)
3. âœ… Regret baseline ì´ˆê¸°í™” ë²„ê·¸ ìˆ˜ì •

**Phase 2 (ë‹¨ê¸°):**
4. ğŸ“ ê¸°ë³¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì¶”ê°€ (ìˆ˜í•™ í•¨ìˆ˜ë“¤)
5. ğŸ“ í•˜ì´í¼íŒŒë¼ë¯¸í„° config ë¶„ë¦¬
6. ğŸ“ `ActionSelector` í´ë˜ìŠ¤ ë¶„í•´ ì‹œì‘

**Phase 3 (ì¤‘ê¸°):**
7. ğŸ”„ í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±
8. ğŸ”„ ë²¡í„°í™” ìµœì í™”
9. ğŸ”„ Regime-based memory ì™„ì„± ë˜ëŠ” ì œê±°

---

## 12. ê²°ë¡ 

### 12.1 ì¢…í•© í‰ê°€

**ì¥ì :**
- âœ… FEP ì›ì¹™ì— ì¶©ì‹¤í•œ ì„¤ê³„
- âœ… ë³µì¡í•œ ë©”ì»¤ë‹ˆì¦˜ë“¤ì´ ì „ë°˜ì ìœ¼ë¡œ ì˜ ì‘ë™
- âœ… ì½”ë“œ ë¬¸ì„œí™”ê°€ ìƒì„¸í•¨
- âœ… ì¬í˜„ì„± ë° ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ ìš°ìˆ˜

**ë‹¨ì :**
- âš ï¸ í…ŒìŠ¤íŠ¸ ë¶€ì¬ë¡œ ì•ˆì •ì„± ê²€ì¦ ì–´ë ¤ì›€
- âš ï¸ ìˆ˜ì¹˜ ì•ˆì •ì„± ê°œì„  í•„ìš”
- âš ï¸ ë³µì¡ë„ê°€ ë†’ì•„ ìœ ì§€ë³´ìˆ˜ ë¶€ë‹´
- âš ï¸ ì¼ë¶€ ì´ë¡ -êµ¬í˜„ ê°„ê·¹ (Ambiguity, Complexity)

### 12.2 ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€

**í˜„ì¬ ìƒíƒœë¡œë„ ì‚¬ìš© ê°€ëŠ¥**: âœ… **ì˜ˆ**

- ì‹¬ê°í•œ ë²„ê·¸ ì—†ìŒ
- ê¸°ë³¸ ê¸°ëŠ¥ ì‘ë™
- Drift ì ì‘ ë©”ì»¤ë‹ˆì¦˜ ì¡´ì¬

**í”„ë¡œë•ì…˜ ì¤€ë¹„ ì—¬ë¶€**: âš ï¸ **ë¶€ë¶„ì **

- ë” ë§ì€ í…ŒìŠ¤íŠ¸ í•„ìš”
- ìˆ˜ì¹˜ ì•ˆì •ì„± ê°œì„  í•„ìš”
- ì—£ì§€ ì¼€ì´ìŠ¤ ê²€ì¦ í•„ìš”

### 12.3 ìµœì¢… ê¶Œì¥ì‚¬í•­

> **ë‹¨ê¸°**: ìˆ˜ì¹˜ ì•ˆì •ì„±ê³¼ í…ŒìŠ¤íŠ¸ë¥¼ ìš°ì„  ê°œì„ í•˜ì—¬ í˜„ì¬ ê¸°ëŠ¥ì˜ ì‹ ë¢°ì„± í™•ë³´
>
> **ì¤‘ê¸°**: ë³µì¡ë„ë¥¼ ì¤„ì´ê¸° ìœ„í•œ ë¦¬íŒ©í† ë§ ë° ì„±ëŠ¥ ìµœì í™”
>
> **ì¥ê¸°**: ì´ë¡ -êµ¬í˜„ ì •í•©ì„±ì„ ë†’ì´ê³  ìƒˆë¡œìš´ FEP ë©”ì»¤ë‹ˆì¦˜ ì¶”ê°€

---

## ë¶€ë¡ A: ì²´í¬ë¦¬ìŠ¤íŠ¸

í”„ë¡œë•ì…˜ ë°°í¬ ì „ í™•ì¸ì‚¬í•­:

- [ ] ìˆ˜ì¹˜ ì•ˆì •ì„± ê°œì„  (safe_log, safe_divide)
- [ ] ê¸°ë³¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± (ìˆ˜í•™ í•¨ìˆ˜)
- [ ] Drift suppression threshold ì‹¤í—˜ ê²€ì¦
- [ ] Regret baseline ë²„ê·¸ ìˆ˜ì •
- [ ] í•˜ì´í¼íŒŒë¼ë¯¸í„° config ë¶„ë¦¬
- [ ] ë¬¸ì„œí™” ê°œì„  (íƒ€ì… íŒíŠ¸, ë°˜í™˜ê°’ ì„¤ëª…)
- [ ] ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ (ë³‘ëª© ì§€ì  í™•ì¸)
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ (ì¥ê¸° ì‹¤í–‰)
- [ ] ì—£ì§€ ì¼€ì´ìŠ¤ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
- [ ] CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

---

**ì‘ì„±ì¼**: 2025-12-29  
**ë²„ì „**: Genesis Brain v4.6.2  
**ë¶„ì„ì**: GitHub Copilot  
**ì´ ì½”ë“œ ë¼ì¸ ìˆ˜**: ~10,157 ì¤„
